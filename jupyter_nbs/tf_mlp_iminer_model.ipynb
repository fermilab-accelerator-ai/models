{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libs && packages.\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.optimize as opt\n",
    "import statsmodels.api as sm\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    # Hidden layer with ReLU activation\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.relu(layer_1)\n",
    "    # # Hidden layer with RELU activation\n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.relu(layer_2)\n",
    "\n",
    "    # Output layer with linear activation\n",
    "    out_layer = tf.matmul(layer_2, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Learning parameters\n",
    "learning_rate = 0.001\n",
    "training_epochs = 50000\n",
    "batch_size = 1000\n",
    "display_step = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# Handle data.\n",
    "df = pd.read_csv('../data/20190606180000-20190606190000.csv')\n",
    "df=df.replace([np.inf, -np.inf], np.nan)\n",
    "df=df.dropna();\n",
    "df=df.round(decimals=5)  # round to one decimal after precision of devices\n",
    "df['diff'] = (df['B_VIMIN'] - df['B:VIMIN'])\n",
    "\n",
    "dep_cols = [ 'diff','B:VIMAX', 'B_VIMAX',  'B:IMAXXO', 'B_VINHBT',   'B:DCPG' , 'B:DCIG', 'B:VIPHAS',\n",
    "                'B:PS1VGP', 'B:PS1VGM', 'B:GMPS1V', 'B:PS2VGP', 'B:PS2VGM',\n",
    "               'B:GMPS2V', 'B:PS3VGP', 'B:PS3VGM', 'B:GMPS3V', 'B:PS4VGP', 'B:PS4VGM', 'B:GMPS4V','err_prev','y']\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "df['err_prev'] = df['B:IMINER'].shift(1)#iloc[1:len(df['B:IMINER'])]\n",
    "df['y'] = df['B:IMINER']\n",
    "# Taking the data we're focused on.\n",
    "df2=df[dep_cols]\n",
    "#df2['index'] = df['time_B:VIMIN']\n",
    "#df2=df2.set_index(pd.DatetimeIndex(df2['index'])) # set index to time (not in-place operation)\n",
    "df2=df2.dropna(axis=0)\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df2 = pd.DataFrame(scaler.fit_transform(df2))\n",
    "df2.columns = dep_cols\n",
    "dep_cols.remove('y')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       diff   B:VIMAX   B_VIMAX  B:IMAXXO  B_VINHBT  B:DCPG  B:DCIG  B:VIPHAS  \\\n",
      "0  0.872654  0.497239  0.630427       0.0       0.0     0.0     0.0  0.498181   \n",
      "1  0.863452  0.621472  0.630427       0.0       0.0     0.0     0.0  0.495756   \n",
      "2  0.868715  0.536774  0.630427       0.0       0.0     0.0     0.0  0.494370   \n",
      "3  0.867996  0.649657  0.630427       0.0       0.0     0.0     0.0  0.494370   \n",
      "4  0.870279  0.587550  0.630427       0.0       0.0     0.0     0.0  0.497662   \n",
      "\n",
      "   B:PS1VGP  B:PS1VGM  ...  B:PS2VGM  B:GMPS2V  B:PS3VGP  B:PS3VGM  B:GMPS3V  \\\n",
      "0  0.105263  0.540540  ...  0.659091  0.222973  0.473684  0.714286  0.349869   \n",
      "1  0.052632  0.513513  ...  0.681818  0.326014  0.421053  0.642857  0.195822   \n",
      "2  0.122807  0.567568  ...  0.681818  0.172297  0.421053  0.642857  0.195822   \n",
      "3  0.157895  0.594595  ...  0.659091  0.172297  0.421053  0.607143  0.083551   \n",
      "4  0.368421  0.567568  ...  0.727273  0.537162  0.421053  0.642857  0.138381   \n",
      "\n",
      "   B:PS4VGP  B:PS4VGM  B:GMPS4V  err_prev         y  \n",
      "0  0.666667  0.846154  0.163717  0.522422  0.495516  \n",
      "1  0.733333  0.820513  0.044248  0.495516  0.457399  \n",
      "2  0.733333  0.820513  0.044248  0.457399  0.479821  \n",
      "3  0.666667  0.846154  0.597345  0.479821  0.479821  \n",
      "4  0.733333  0.820513  0.008850  0.479821  0.486547  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "print(df2.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            count      mean       std       min       25%       50%       75%  \\\n",
      "diff      38485.0  0.869876  0.043363  0.054836  0.856339  0.871101  0.886149   \n",
      "B:VIMAX   38485.0  0.572780  0.089611  0.000000  0.514201  0.576308  0.632696   \n",
      "B_VIMAX   38485.0  0.611210  0.052441  0.000000  0.565208  0.630427  0.630427   \n",
      "B:IMAXXO  38485.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "B_VINHBT  38485.0  0.000000  0.000000  0.000000  0.000000  0.000000  0.000000   \n",
      "\n",
      "          max  \n",
      "diff      1.0  \n",
      "B:VIMAX   1.0  \n",
      "B_VIMAX   1.0  \n",
      "B:IMAXXO  0.0  \n",
      "B_VINHBT  0.0  \n"
     ]
    }
   ],
   "source": [
    "train_data = df2.sample(n = int(0.8*len(df2['diff'])), random_state = 42)\n",
    "test_data =  df2.drop(train_data.index)\n",
    "\n",
    "train_stats = train_data.describe()\n",
    "train_stats = train_stats.transpose()\n",
    "test_stats = test_data.describe()\n",
    "test_stats = test_stats.transpose()\n",
    "print(train_stats.head())\n",
    "\n",
    "def standardize(x,stats):\n",
    "  return (x - stats['mean']) / stats['std']\n",
    "standard_train_data = standardize(train_data, train_stats)\n",
    "standard_test_data = standardize(test_data, test_stats)\n",
    "\n",
    "train_data = standard_train_data\n",
    "test_data  = standard_test_data\n",
    "\n",
    "train_data.head()\n",
    "train_data = train_data.dropna(axis=1) # drop columns that are just constants or data of 0.0\n",
    "train_data.head()\n",
    "dep_cols = list(train_data.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Network Parameters\n",
    "n_input =  len(dep_cols)   # layer 0 (input layer) number of features\n",
    "n_hidden_1 = 10 # layer 1 number of features\n",
    "n_hidden_2 = 10 # layer 2 number of features\n",
    "n_output = 1;\n",
    "\n",
    "\n",
    "# Store layers weight && bias\n",
    "weights = {\n",
    "    'h1': tf.Variable(tf.random_uniform([n_input, n_hidden_1])),\n",
    "    'h2': tf.Variable(tf.random_uniform([n_hidden_1, n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_uniform([n_hidden_2, n_output]))\n",
    "}\n",
    "biases = {\n",
    "    'b1': tf.Variable(tf.random_uniform([n_hidden_1])),\n",
    "    'b2': tf.Variable(tf.random_uniform([n_hidden_2])),\n",
    "    'out': tf.Variable(tf.random_uniform([n_output]))\n",
    "}\n",
    "\n",
    "x_data = tf.placeholder(tf.float32, [None, n_input])\n",
    "y_data = tf.placeholder(tf.float32, [None, n_output])\n",
    "\n",
    "# Construct model\n",
    "pred = multilayer_perceptron(x_data, weights, biases)\n",
    "\n",
    "# Build optimizer. Use mean-squared error for loss.\n",
    "loss = tf.reduce_mean(tf.square(pred - y_data))\n",
    "optimizer = tf.train.GradientDescentOptimizer(learning_rate)\n",
    "train = optimizer.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step  |   x    |   y    |      prediction     |     mean-squared error\n",
      "1     | 0.6594  | 0.0002 |  -13.762499809265137 | 189.41419982910156\n",
      "2     | -0.0604  | -0.4053 |  -0.17319999635219574 | 0.05389999970793724\n",
      "3     | -1.0259  | 0.2777 |  -0.17499999701976776 | 0.20489999651908875\n",
      "4     | -0.4792  | -0.7469 |  -0.7822999954223633 | 0.0013000000035390258\n",
      "5     | -0.1335  | -0.2559 |  -0.4154999852180481 | 0.025499999523162842\n",
      "6     | 0.1585  | 0.1924 |  0.28299999237060547 | 0.008200000040233135\n",
      "7     | -0.8097  | -1.2805 |  -0.11739999800920486 | 1.3528000116348267\n",
      "8     | -0.2841  | -0.7255 |  -0.4422000050544739 | 0.08030000329017639\n",
      "9     | 0.3075  | 0.3845 |  0.27140000462532043 | 0.012799999676644802\n",
      "10     | 1.2227  | 1.7933 |  1.7620999813079834 | 0.0010000000474974513\n",
      "11     | 0.4486  | 0.6193 |  0.7175999879837036 | 0.009700000286102295\n",
      "12     | -16.9112  | -1.3232 |  -0.9745000004768372 | 0.12160000205039978\n",
      "13     | 0.3662  | 0.8541 |  1.1654000282287598 | 0.09690000116825104\n",
      "14     | -0.2931  | -0.1919 |  -0.31790000200271606 | 0.01590000092983246\n",
      "15     | -0.6299  | -1.1738 |  -1.2956000566482544 | 0.014800000004470348\n",
      "16     | -0.2279  | -0.1065 |  0.09109999984502792 | 0.03909999877214432\n",
      "17     | 0.7434  | 1.5799 |  1.5745999813079834 | 0.0\n",
      "18     | 0.0135  | -0.4694 |  -0.5268999934196472 | 0.0032999999821186066\n",
      "19     | 0.6622  | 1.5799 |  1.56850004196167 | 9.999999747378752e-05\n",
      "20     | 0.0908  | 2.8393 |  2.200200080871582 | 0.4083999991416931\n",
      "21     | -0.0118  | 0.4272 |  0.6182000041007996 | 0.0364999994635582\n",
      "22     | 0.4865  | 0.5339 |  0.8504999876022339 | 0.10019999742507935\n",
      "23     | 0.1172  | 0.107 |  0.021299999207258224 | 0.007300000172108412\n",
      "24     | -0.3392  | -0.6615 |  -0.9663000106811523 | 0.09290000051259995\n",
      "25     | 2.1791  | -0.3199 |  0.21739999949932098 | 0.28870001435279846\n",
      "26     | 0.6203  | 0.662 |  0.8101999759674072 | 0.02199999988079071\n",
      "27     | 0.7035  | 0.4485 |  0.6879000067710876 | 0.05730000138282776\n",
      "28     | 0.2046  | 0.0002 |  0.06129999831318855 | 0.003700000001117587\n",
      "29     | 0.346  | 0.7047 |  0.399399995803833 | 0.09319999814033508\n",
      "30     | -0.0863  | -0.2132 |  -0.2754000127315521 | 0.0038999998942017555\n",
      "31     | 1.2033  | 1.772 |  1.722100019454956 | 0.0024999999441206455\n",
      "32     | 0.2555  | 0.0429 |  -0.00430000014603138 | 0.002199999988079071\n",
      "33     | 0.9649  | 1.4304 |  0.9365000128746033 | 0.24400000274181366\n",
      "34     | 0.889  | 0.6406 |  0.9312999844551086 | 0.08449999988079071\n",
      "35     | -0.0638  | -0.1705 |  -0.3325999975204468 | 0.02630000002682209\n",
      "36     | -1.0871  | 1.1102 |  1.1373000144958496 | 0.000699999975040555\n",
      "37     | 0.2611  | 0.6833 |  0.9656000137329102 | 0.07970000058412552\n",
      "38     | -0.7355  | -1.1738 |  -1.148300051689148 | 0.0006000000284984708\n",
      "39     | 0.4025  | 0.8114 |  0.7925000190734863 | 0.00039999998989515007\n",
      "40     | -1.3308  | -2.1771 |  -2.2906999588012695 | 0.012900000438094139\n",
      "41     | -0.1686  | -0.1065 |  -0.2176000028848648 | 0.012400000356137753\n",
      "42     | -0.0348  | -0.1278 |  -0.4683000147342682 | 0.11590000241994858\n",
      "43     | -0.4354  | -0.7255 |  -0.7692000269889832 | 0.0019000000320374966\n",
      "44     | 0.2994  | -0.7042 |  -0.878600001335144 | 0.030400000512599945\n",
      "45     | 0.2586  | 0.3418 |  0.4634000062942505 | 0.014800000004470348\n",
      "46     | 0.1465  | 1.0035 |  1.020900011062622 | 0.0003000000142492354\n",
      "47     | -0.0624  | -0.0638 |  -0.028999999165534973 | 0.0012000000569969416\n",
      "48     | -0.5121  | 1.4731 |  1.8746000528335571 | 0.16120000183582306\n",
      "49     | 0.5773  | 0.8754 |  0.993399977684021 | 0.013899999670684338\n",
      "50     | 0.2895  | 0.3845 |  0.5756000280380249 | 0.0364999994635582\n"
     ]
    }
   ],
   "source": [
    "test_step=0\n",
    "# Initialize variables. \n",
    "init = tf.global_variables_initializer()\n",
    "# Begin session.\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "print(\"step  |   x    |   y    |      prediction     |     mean-squared error\")\n",
    "for step in range(training_epochs):\n",
    "    train_samp = train_data.sample(n=batch_size, random_state = step)\n",
    "    x_in = np.array(train_samp[dep_cols].values)\n",
    "    # x_in = x_in.flatten()\n",
    "    y_in = np.array(train_samp['y'].values)\n",
    "    # x_in = x_in.reshape(-1,1)\n",
    "    y_in = y_in.reshape(-1,1)\n",
    "    sess.run(train, feed_dict = {x_data: x_in, y_data: y_in})  \n",
    "    if(step % display_step == 0):\n",
    "        test_step += 1\n",
    "        test_samp =  test_data.sample(n=1,random_state = step)        \n",
    "        x_test = np.array(test_samp[dep_cols].values)\n",
    "        # x_test = np.transpose(x_test)\n",
    "        y_test = np.array(test_samp['y'].values)\n",
    "        y_test = y_test.reshape(-1,1)\n",
    "\n",
    "        test_pred = sess.run(pred, feed_dict={x_data: x_test})\n",
    "        test_loss = sess.run(loss, feed_dict={x_data: x_test, y_data: y_test})\n",
    "        \n",
    "        print(\"{0}     | {1}  | {2} |  {3} | {4}\".format(test_step, round(x_test[0][0],4), round(y_test[0][0],4),np.round(test_pred[0][0],4), round(test_loss,4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mse over test set:  0.037206274\n"
     ]
    }
   ],
   "source": [
    "x_test_f = np.array(test_data[dep_cols].values)\n",
    "x_test_f = np.transpose(x_test)\n",
    "y_test_f = np.array(test_data['y'].values)\n",
    "y_test_f = y_test_f.reshape(-1,1)\n",
    "test_samp = sess.run(pred, feed_dict={x_data: x_test})\n",
    "test_loss = sess.run(loss, feed_dict={x_data: x_test, y_data: y_test})\n",
    "print('mse over test set: ', test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
