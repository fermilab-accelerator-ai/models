{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from math import sqrt\n",
    "from matplotlib import pyplot as plt\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, LSTM\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify model for data handling\n",
    "# design network\n",
    "n_hidden1 = 10\n",
    "activation1 = 'relu'\n",
    "activation2 = 'relu'\n",
    "n_hidden2 = 10\n",
    "EPOCHS = 100\n",
    "BATCH_SIZE = 100\n",
    "\n",
    "rnn_flag = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create directory for Tensorboard\n",
    "import os, time, datetime\n",
    "stamp = datetime.datetime.now()\n",
    "stamp = time.mktime(stamp.timetuple())\n",
    "cwd = os.getcwd()\n",
    "PATH_TO_LOG = cwd+'\\\\tfboards\\\\run_'+str(stamp) + '_' + activation1 +'x'+activation2 + '-' +str(n_hidden1) + 'x' + str(n_hidden2)\n",
    "os.mkdir(PATH_TO_LOG)\n",
    "tensorboard_callback = keras.callbacks.TensorBoard(log_dir=PATH_TO_LOG)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3049: DtypeWarning: Columns (77,79,81,83,85,87) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48004, 3)\n"
     ]
    }
   ],
   "source": [
    "# Handle data.\n",
    "df = pd.read_csv('../data/20190606180000-20190606190000.csv')\n",
    "df=df.replace([np.inf, -np.inf], np.nan)\n",
    "df=df.dropna(axis=0);\n",
    "\n",
    "\n",
    "# columns of interest\n",
    "cols = ['B:VIMIN', 'B_VIMIN','B:IMINER']\n",
    "\n",
    "# Extract data we're focused on\n",
    "df2=df[cols]\n",
    "#df2=df2.set_index(pd.DatetimeIndex(df2['time'])) # set index to time (not in-place operation)\n",
    "\n",
    "# clean data: remove rows with spurious values of B:VIMIN (>= 3 stdevs)\n",
    "std_vimin  = np.std(df['B:VIMIN'])\n",
    "mean_vimin = np.mean(df['B:VIMIN'])\n",
    "df2=df2[df2['B:VIMIN']< mean_vimin + 3*std_vimin]\n",
    "print(df2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTION: series_to_supervised\n",
    "# INPUT: data   ~ numpy array of time series observations\n",
    "#       n_lag   ~ number of lag observations as input \n",
    "#       n_out   ~ number of observations as output.\n",
    "#       dropnan ~ Boolean whether or not to drop rows with NaN values.\n",
    "# sourced: https://machinelearningmastery.com/multivariate-time-series-forecasting-lstms-keras/\n",
    "def series_to_supervised(data, n_lag=1, n_out=1, dropnan=True):\n",
    "    n_vars = 1 if type(data) is list else data.shape[1]\n",
    "    df = pd.DataFrame(data)\n",
    "    col_data = []\n",
    "    col_names = []\n",
    "    # build the input sequence by concatenating farthest to closest in time\n",
    "    for i in range(n_lag, 0, -1):\n",
    "        col_data.append(df.shift(i))\n",
    "        col_names += [('var%d(t-%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    # build the output sequence\n",
    "    for i in range(0, n_out):\n",
    "        col_data.append(df.shift(-i))\n",
    "        if i == 0:\n",
    "            col_names += [('x%d(t)' % (j+1)) for j in range(n_vars)]\n",
    "        else:\n",
    "            col_names += [('x%d(t+%d)' % (j+1, i)) for j in range(n_vars)]\n",
    "    agg = pd.concat(col_data, axis=1)\n",
    "    agg.columns =col_names\n",
    "    # drop rows with NaN values\n",
    "    if dropnan:\n",
    "        agg.dropna(inplace=True)\n",
    "    return agg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# select B:VIMIN to convert to lagged time series\n",
    "cycle  = 15\n",
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "df_xy  = pd.DataFrame(scaler.fit_transform(df2.values))\n",
    "# convert B:VIMIN to lagged series\n",
    "df_ts = pd.DataFrame(series_to_supervised(list(df_xy.iloc[:,0]),cycle))\n",
    "df_ts=df_ts.reset_index()\n",
    "\n",
    "# join lagged time series with the non-lagged features AND target: B_VIMIN (a feature) and target \n",
    "data = pd.concat([df_ts, df_xy.iloc[:, 1:]], axis = 1,ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data.drop(data.columns[0],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(38391, 17) (38391,) (9598, 17) (9598,)\n"
     ]
    }
   ],
   "source": [
    "p = 0.8 # percent of data to take\n",
    "n_train = int(len(data)* p)\n",
    "\n",
    "\n",
    "train = data.sample(n= n_train, random_state = 42)\n",
    "test = data.drop(train.index)\n",
    "\n",
    "\n",
    "# split into input and outputs\n",
    "x_train, y_train = train.iloc[:, :-1], train.iloc[:, -1]\n",
    "x_test, y_test = test.iloc[:, :-1], test.iloc[:, -1]\n",
    "\n",
    "#L RNN LSTM Model only\n",
    "if rnn_flag == True:\n",
    "# reshape input to be 3D [samples, timesteps, features]\n",
    "    x_train = x_train.reshape((x_train.shape[0], 1, x_train.shape[1]))\n",
    "    x_test = x_test.reshape((x_test.shape[0], 1, x_test.shape[1]))\n",
    "print(x_train.shape, y_train.shape, x_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W0806 20:49:57.325581 15452 deprecation_wrapper.py:118] From C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:74: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "W0806 20:49:57.351126 15452 deprecation_wrapper.py:118] From C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:517: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
      "\n",
      "W0806 20:49:57.359193 15452 deprecation_wrapper.py:118] From C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:4138: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
      "\n",
      "W0806 20:49:57.411992 15452 deprecation_wrapper.py:118] From C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\keras\\optimizers.py:790: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "W0806 20:49:57.567309 15452 deprecation_wrapper.py:118] From C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:986: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n",
      "\n",
      "W0806 20:49:57.576057 15452 deprecation_wrapper.py:118] From C:\\Users\\Rachael\\.conda\\envs\\py3tf1gnt\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:973: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 38391 samples, validate on 9598 samples\n",
      "Epoch 1/100\n",
      " - 2s - loss: 0.1090 - mean_absolute_error: 0.1090 - val_loss: 0.0685 - val_mean_absolute_error: 0.0685\n",
      "Epoch 2/100\n",
      " - 1s - loss: 0.0653 - mean_absolute_error: 0.0653 - val_loss: 0.0608 - val_mean_absolute_error: 0.0608\n",
      "Epoch 3/100\n",
      " - 1s - loss: 0.0596 - mean_absolute_error: 0.0596 - val_loss: 0.0564 - val_mean_absolute_error: 0.0564\n",
      "Epoch 4/100\n",
      " - 0s - loss: 0.0563 - mean_absolute_error: 0.0563 - val_loss: 0.0563 - val_mean_absolute_error: 0.0563\n",
      "Epoch 5/100\n",
      " - 1s - loss: 0.0546 - mean_absolute_error: 0.0546 - val_loss: 0.0547 - val_mean_absolute_error: 0.0547\n",
      "Epoch 6/100\n",
      " - 2s - loss: 0.0537 - mean_absolute_error: 0.0537 - val_loss: 0.0521 - val_mean_absolute_error: 0.0521\n",
      "Epoch 7/100\n",
      " - 2s - loss: 0.0531 - mean_absolute_error: 0.0531 - val_loss: 0.0520 - val_mean_absolute_error: 0.0520\n",
      "Epoch 8/100\n",
      " - 2s - loss: 0.0526 - mean_absolute_error: 0.0526 - val_loss: 0.0519 - val_mean_absolute_error: 0.0519\n",
      "Epoch 9/100\n",
      " - 2s - loss: 0.0522 - mean_absolute_error: 0.0522 - val_loss: 0.0530 - val_mean_absolute_error: 0.0530\n",
      "Epoch 10/100\n"
     ]
    }
   ],
   "source": [
    "# Construct Newtork\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Dense(n_hidden1, activation=activation1, input_dim=(x_train.shape[1]))) # input to hidden1\n",
    "model.add(Dense(n_hidden2, activation=activation2)) # hidden1 to hidden2\n",
    "model.add(Dense(1, activation='linear')) # output layer\n",
    "\n",
    "\n",
    "model.compile(optimizer='rmsprop',\n",
    "              loss='mae',\n",
    "              metrics=['mae'])\n",
    "\n",
    "# fit network\n",
    "history = model.fit(x_train, y_train, epochs=EPOCHS, batch_size=BATCH_SIZE, validation_data=(x_test, y_test), verbose=2, shuffle=False, callbacks=[tensorboard_callback])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
